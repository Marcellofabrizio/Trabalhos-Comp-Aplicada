---
title: "Tarefa 2 - Preparação de Dados"
author: "Leonardo Martelli e Marcello Fabrizio"
date: "24/10/2021"
output:
  html_document:
    df_print: paged
  pdf_document: default
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

### 0 - Limpeza do ambiente e carregamento de pacotes0

```{r packs, warning=FALSE, message = FALSE}
rm(list=ls())

library('ggplot2')
library('gridExtra')
library('GGally')
library(grid)
library(stringr)
library(corrplot)
library(caret)
```

### 1 - Carregue a base de dados e mostre a estrutura do dataset (str()). O arquivo do dataset não pode ser modificado de forma alguma. A leitura deverá tratar qualquer característica do arquivo.

```{r load data, warning=FALSE, message=FALSE}
beans_data = read.csv("Dry_Bean_Dataset.csv",header=T, sep=";", na.strings="?", dec=",")
str(beans_data)
```

### 2 - Altere a variável do tipo do feijão (Class) para um factor. 
```{r factor, warning=FALSE, message=FALSE}
class_factor = factor(beans_data$Class)
beans_data$Class = class_factor
```

### 3 - Plote um gráfico de barras que ilustre as quantidades de cada classe.
```{r bar plot, warning=FALSE, message=FALSE}
ggplot(beans_data, aes(Class, fill = Class)) + geom_bar() + theme(legend.position = "none")
```

### 4 - Realize a normalização dos dados via Z-score. Plote um boxplot para ilustrar a distribuição de cada variável. Mostre as estatísticas de cada variável (summary). 
```{r normalization, warning=FALSE, message=FALSE}


for (var in names(beans_data[1:16])) {
  mean    = mean(beans_data[[var]])
  sd      = sd(beans_data[[var]])
  z_score = (beans_data[[var]] - mean)/sd
  
  beans_data[[var]] = z_score
}

#scale obtem o mesmo resultado do que acima
#z_score = as.data.frame(scale(beans_data[,1:16]))

summary(beans_data)

classes = unique(beans_data$Class)

num_classes = length(classes)

colors=c("red", "green", "blue")

par(mfrow=c(1,3), cex=0.5)
for(i in 1:3){
  plot <- boxplot(beans_data[,i] ~ beans_data$Class, 
                  col=colors, xlab = "", 
                  ylab="", 
                  main = names(beans_data)[i], 
                  xaxt = "n",  
                  yaxt = "n")
  axis(side = 1, labels = FALSE)
  axis(side = 2, las = 2, cex.axis = 0.9, font =20)
  text(x = 1:num_classes,
       labels = classes,
       par("usr")[3],
       xpd = T,
       srt = 90,
       adj = 1.2,
       cex = 0.9)
}

par(mfrow=c(1,3), cex=0.5)
for(i in 4:6){
  plot <- boxplot(beans_data[,i] ~ beans_data$Class, 
                  col=colors, xlab = "", 
                  ylab="", 
                  main = names(beans_data)[i], 
                  xaxt = "n",  
                  yaxt = "n")
  axis(side = 1, labels = FALSE)
  axis(side = 2, las = 2, cex.axis = 0.9, font =20)
  text(x = 1:num_classes,
       labels = classes,
       par("usr")[3],
       xpd = T,
       srt = 90,
       adj = 1.2,
       cex = 0.9)
}

par(mfrow=c(1,3), cex=0.5)
for(i in 7:9){
  plot <- boxplot(beans_data[,i] ~ beans_data$Class, 
                  col=colors, xlab = "", 
                  ylab="", 
                  main = names(beans_data)[i], 
                  xaxt = "n",  
                  yaxt = "n")
  axis(side = 1, labels = FALSE)
  axis(side = 2, las = 2, cex.axis = 0.9, font =20)
  text(x = 1:num_classes,
       labels = classes,
       par("usr")[3],
       xpd = T,
       srt = 90,
       adj = 1.2,
       cex = 0.9)
}

par(mfrow=c(1,3), cex=0.5)
for(i in 10:12){
  plot <- boxplot(beans_data[,i] ~ beans_data$Class, 
                  col=colors, xlab = "", 
                  ylab="", 
                  main = names(beans_data)[i], 
                  xaxt = "n",  
                  yaxt = "n")
  axis(side = 1, labels = FALSE)
  axis(side = 2, las = 2, cex.axis = 0.9, font =20)
  text(x = 1:num_classes,
       labels = classes,
       par("usr")[3],
       xpd = T,
       srt = 90,
       adj = 1.2,
       cex = 0.9)
}

par(mfrow=c(1,3), cex=0.5)
for(i in 13:15){
  plot <- boxplot(beans_data[,i] ~ beans_data$Class, 
                  col=colors, xlab = "", 
                  ylab="", 
                  main = names(beans_data)[i], 
                  xaxt = "n",  
                  yaxt = "n")
  axis(side = 1, labels = FALSE)
  axis(side = 2, las = 2, cex.axis = 0.9, font =20)
  text(x = 1:num_classes,
       labels = classes,
       par("usr")[3],
       xpd = T,
       srt = 90,
       adj = 1.2,
       cex = 0.9)
}

par(mfrow=c(1,3), cex=0.5)
for(i in 16:16){
  plot <- boxplot(beans_data[,i] ~ beans_data$Class, 
                  col=colors, xlab = "", 
                  ylab="", 
                  main = names(beans_data)[i], 
                  xaxt = "n",  
                  yaxt = "n")
  axis(side = 1, labels = FALSE)
  axis(side = 2, las = 2, cex.axis = 0.9, font =20)
  text(x = 1:num_classes,
       labels = classes,
       par("usr")[3],
       xpd = T,
       srt = 90,
       adj = 1.2,
       cex = 0.9)
}
```

### 5 - Realize a seleção de características (correlação). Plote o gráfico de correlação. Liste as características que foram removidas. 
```{r correlation matrix, message=FALSE, warning=FALSE}

correlation_matrix = cor(beans_data[1:16])

strong_correlations = findCorrelation(correlation_matrix, cutoff=0.95)

if(length(strong_correlations) > 0) {
  beans_data[,strong_correlations] = NULL
}

corrplot(correlation_matrix)

summary(beans_data)
```
Foi utilizada a função findCorrelation para obter os indices que denotam as colunas a serem removidas. Ela os obtem examinando a correlação média de cada variável em um par de variáveis, e remove a variável com correlação acima da taxa de corte. 

### 6 - Plote um gráfico boxplot ou de densidade por variável x classe (organize em 3 colunas). Discuta qual é a variável que teria maior poder de discriminação? Existe alguma classe que pode ser classificada mais facilmente? Justifique a sua escolha.

```{r boxplots, message=FALSE, warning=FALSE}
library(gridExtra)
library(ggplot2)

p = list()
for(i in 1:3){
  p[[i]] = ggplot(beans_data, aes_string(x=names(beans_data)[i],fill="Class")) + 
    geom_density(alpha=0.5,color="darkgray") + 
    theme(legend.position="none", 
          legend.title = element_blank())
}
do.call(grid.arrange,c(p,ncol=3))

p = list()
for(i in 4:6){
  p[[i - 3]] = ggplot(beans_data, aes_string(x=names(beans_data)[i],fill="Class")) + 
    geom_density(alpha=0.5,color="darkgray") + 
    theme(legend.position="none", 
          legend.title = element_blank())
}

do.call(grid.arrange,c(p,ncol=3))

p = list()
for(i in 7:9){
  p[[i - 6]] = ggplot(beans_data, aes_string(x=names(beans_data)[i],fill="Class")) + 
    geom_density(alpha=0.5,color="darkgray") + 
    theme(legend.position="none", 
          legend.title = element_blank())
}
do.call(grid.arrange, c(p,ncol=3))

p = list()
for(i in 10){
  p[[i-9]] = ggplot(beans_data, aes_string(x=names(beans_data)[i],fill="Class")) + 
    geom_density(alpha=0.5,color="darkgray") + 
    theme(legend.position="none", 
          legend.title = element_blank())
}

do.call(grid.arrange,c(p,ncol=1))
```
A classe Bombay apresenta um maior poder de discriminação comparada com as demais.

### 7 - Realize a projeção do dataset utilizando PCA. Explique as características dos componentes principais estimados. O que se pode explicar sobre os componentes principais utilizando o gráfico biplot. Apresente as características básicas (summary) dos dados.

```{r PCA, warning=FALSE, message=FALSE}
sigma = cov(beans_data[,1:9])
eigen = eigen(sigma)

print(eigen)

pca = prcomp(beans_data[,1:9], center=TRUE, scale=TRUE)

summary(pca)

predicted_data = predict(pca, beans_data)

summary(predicted_data)

biplot(pca,xlabs = rep("", nrow(beans_data[,1:9])))
```
